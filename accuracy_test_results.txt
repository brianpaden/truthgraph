============================= test session starts =============================
platform win32 -- Python 3.13.7, pytest-8.4.2, pluggy-1.6.0 -- C:\python313\python.exe
cachedir: .pytest_cache
rootdir: c:\repos\truthgraph
configfile: pytest.ini
plugins: anyio-4.11.0, asyncio-1.2.0, cov-7.0.0
asyncio: mode=Mode.AUTO, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 43 items

tests/accuracy/test_accuracy_baseline.py::test_real_world_claims_fixture_exists PASSED [  2%]
tests/accuracy/test_accuracy_baseline.py::test_real_world_evidence_fixture_exists PASSED [  4%]
tests/accuracy/test_accuracy_baseline.py::test_real_world_claims_structure PASSED [  6%]
tests/accuracy/test_accuracy_baseline.py::test_real_world_evidence_structure PASSED [  9%]
tests/accuracy/test_accuracy_baseline.py::test_real_world_evidence_references PASSED [ 11%]
tests/accuracy/test_accuracy_baseline.py::test_verdict_distribution PASSED [ 13%]
tests/accuracy/test_accuracy_baseline.py::test_category_coverage PASSED  [ 16%]
tests/accuracy/test_accuracy_baseline.py::test_real_world_claims_by_category PASSED [ 18%]
tests/accuracy/test_accuracy_baseline.py::test_real_world_claims_by_verdict PASSED [ 20%]
tests/accuracy/test_accuracy_baseline.py::test_accuracy_results_tracking PASSED [ 23%]
tests/accuracy/test_accuracy_baseline.py::test_accuracy_results_serialization PASSED [ 25%]
tests/accuracy/test_accuracy_baseline.py::test_baseline_accuracy SKIPPED [ 27%]
tests/accuracy/test_ml_accuracy.py::TestNLIAccuracy::test_nli_accuracy_overall PASSED [ 30%]
tests/accuracy/test_ml_accuracy.py::TestNLIAccuracy::test_nli_entailment_accuracy PASSED [ 32%]
tests/accuracy/test_ml_accuracy.py::TestNLIAccuracy::test_nli_contradiction_accuracy PASSED [ 34%]
tests/accuracy/test_ml_accuracy.py::TestNLIAccuracy::test_nli_neutral_accuracy PASSED [ 37%]
tests/accuracy/test_ml_accuracy.py::TestNLIAccuracy::test_nli_confidence_calibration PASSED [ 39%]
tests/accuracy/test_ml_accuracy.py::TestNLIAccuracy::test_nli_long_text_handling PASSED [ 41%]
tests/accuracy/test_ml_accuracy.py::TestNLIAccuracy::test_nli_negation_handling PASSED [ 44%]
tests/accuracy/test_ml_accuracy.py::TestVerdictAggregationAccuracy::test_aggregation_all_entailment PASSED [ 46%]
tests/accuracy/test_ml_accuracy.py::TestVerdictAggregationAccuracy::test_aggregation_all_contradiction PASSED [ 48%]
tests/accuracy/test_ml_accuracy.py::TestVerdictAggregationAccuracy::test_aggregation_mixed_evidence PASSED [ 51%]
tests/accuracy/test_ml_accuracy.py::TestVerdictAggregationAccuracy::test_aggregation_confidence_weighting PASSED [ 53%]
tests/accuracy/test_ml_accuracy.py::TestVerdictAggregationAccuracy::test_aggregation_all_neutral PASSED [ 55%]
tests/accuracy/test_ml_accuracy.py::TestVerdictAggregationAccuracy::test_aggregation_test_dataset PASSED [ 58%]
tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_search_precision_at_5 PASSED [ 60%]
tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_search_recall_at_10 FAILED [ 62%]
tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_search_mrr_metric PASSED [ 65%]
tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_search_ndcg_metric PASSED [ 67%]
tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_vector_search_relevance PASSED [ 69%]
tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_hybrid_search_relevance PASSED [ 72%]
tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_search_on_hard_queries PASSED [ 74%]
tests/accuracy/test_ml_accuracy.py::TestEmbeddingQuality::test_embedding_dimension PASSED [ 76%]
tests/accuracy/test_ml_accuracy.py::TestEmbeddingQuality::test_embedding_normalization PASSED [ 79%]
tests/accuracy/test_ml_accuracy.py::TestEmbeddingQuality::test_embedding_similarity_correctness PASSED [ 81%]
tests/accuracy/test_ml_accuracy.py::TestEmbeddingQuality::test_embedding_dissimilarity_correctness PASSED [ 83%]
tests/accuracy/test_ml_accuracy.py::TestEmbeddingQuality::test_embedding_consistency PASSED [ 86%]
tests/accuracy/test_ml_accuracy.py::TestEmbeddingQuality::test_embedding_model_version PASSED [ 88%]
tests/accuracy/test_ml_accuracy.py::TestIntegrationAccuracy::test_end_to_end_accuracy_on_test_dataset PASSED [ 90%]
tests/accuracy/test_ml_accuracy.py::TestIntegrationAccuracy::test_accuracy_by_claim_complexity PASSED [ 93%]
tests/accuracy/test_ml_accuracy.py::TestIntegrationAccuracy::test_accuracy_by_evidence_availability PASSED [ 95%]
tests/accuracy/test_ml_accuracy.py::TestIntegrationAccuracy::test_false_positive_rate PASSED [ 97%]
tests/accuracy/test_ml_accuracy.py::TestIntegrationAccuracy::test_false_negative_rate PASSED [100%]

================================== FAILURES ===================================
________________ TestSearchRelevance.test_search_recall_at_10 _________________
tests\accuracy\test_ml_accuracy.py:572: in test_search_recall_at_10
    assert len(test_case.evidence_documents) >= 10
E   AssertionError: assert 8 >= 10
E    +  where 8 = len(['Global warming caused by human activities increases temperatures', 'CO2 emissions from fossil fuels contribute to climate change', 'Ocean levels are rising due to melting polar ice', 'The best recipes for chocolate cake', 'Climate change leads to extreme weather events', 'How to train a dog', ...])
E    +    where ['Global warming caused by human activities increases temperatures', 'CO2 emissions from fossil fuels contribute to climate change', 'Ocean levels are rising due to melting polar ice', 'The best recipes for chocolate cake', 'Climate change leads to extreme weather events', 'How to train a dog', ...] = SearchRelevanceTestCase(query='climate change impacts', evidence_documents=['Global warming caused by human activities increases temperatures', 'CO2 emissions from fossil fuels contribute to climate change', 'Ocean levels are rising due to melting polar ice', 'The best recipes for chocolate cake', 'Climate change leads to extreme weather events', 'How to train a dog', 'The impact of deforestation on climate', 'Best places to visit in Europe'], relevant_indices=[0, 1, 2, 4, 6], description='Climate change query with multiple relevant documents').evidence_documents
============================== warnings summary ===============================
truthgraph\db.py:27
  c:\repos\truthgraph\truthgraph\db.py:27: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED tests/accuracy/test_ml_accuracy.py::TestSearchRelevance::test_search_recall_at_10
============= 1 failed, 41 passed, 1 skipped, 1 warning in 5.13s ==============
