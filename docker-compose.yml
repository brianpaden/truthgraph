# TruthGraph v0 Development Stack with ML Services
# Includes: PostgreSQL + pgvector, FastAPI backend with ML, htmx frontend, React frontend (optional)
#
# ML Services Configuration:
# - Sentence-Transformers (all-MiniLM-L6-v2) for embeddings
# - DeBERTa-v3-base for natural language inference
# - Model cache persisted across restarts
# - GPU support optional (set DOCKER_USE_GPU=true to enable)
#
# Build Context: docker/api.Dockerfile (optimized multi-stage build)
# Resource Limits: 4GB memory per service, configurable CPU
#
# Quick Start:
#   docker-compose up
#   Models download automatically on first run (~520MB total)
#
# With GPU Support:
#   docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up
#
# Model Cache Location:
#   ./.volumes/models/  (persists between runs)

services:
  # PostgreSQL with pgvector extension for semantic search
  postgres:
    image: pgvector/pgvector:pg16
    container_name: truthgraph-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-truthgraph}
      POSTGRES_USER: ${POSTGRES_USER:-truthgraph}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    volumes:
      - ./.volumes/postgres:/var/lib/postgresql/data
      - ./docker/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-truthgraph}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - truthgraph-network
    deploy:
      resources:
        limits:
          memory: 2G

  # FastAPI Backend with ML Services
  # Uses optimized multi-stage Dockerfile for faster builds
  # Includes torch, transformers, sentence-transformers
  api:
    build:
      context: .
      dockerfile: docker/api.Dockerfile
    container_name: truthgraph-api
    environment:
      # Database Configuration
      DATABASE_URL: postgresql+psycopg://${POSTGRES_USER:-truthgraph}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-truthgraph}
      # Test database URL (for integration tests)
      TEST_DATABASE_URL: postgresql+psycopg://${POSTGRES_USER:-truthgraph}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-truthgraph}

      # Application Configuration
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      API_HOST: ${API_HOST:-0.0.0.0}
      API_PORT: ${API_PORT:-8000}

      # ML Model Cache Configuration
      # Models are downloaded once and cached in named volume
      HF_HOME: /root/.cache/huggingface
      HUGGINGFACE_HUB_CACHE: /root/.cache/huggingface

      # Optional: Set to 1 for offline mode (after initial cache)
      # TRANSFORMERS_OFFLINE: 0

      # Device Configuration (auto-detect GPU if available)
      TORCH_NUM_THREADS: ${TORCH_NUM_THREADS:-4}

    volumes:
      # Model cache volume (persistent across restarts)
      # First startup downloads ~80MB (embeddings) + ~440MB (NLI model)
      - ./.volumes/models:/root/.cache/huggingface

      # Mount source for hot reload in development
      - ./truthgraph:/app/truthgraph:ro
    ports:
      - "${API_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      # Extended start period for ML model loading on first run
      # Models load from cache on subsequent starts
      start_period: ${API_HEALTH_START_PERIOD:-60s}
    networks:
      - truthgraph-network
    deploy:
      resources:
        limits:
          # ML models use less memory with CPU optimization
          # Sentence-Transformers: ~400MB
          # DeBERTa-v3-base: ~700MB
          # Total headroom: 3-4GB typical
          memory: 4G
          # Optional: limit CPU usage if running on shared hardware
          # cpus: "2.0"
        reservations:
          # Requested memory (affects placement decisions)
          memory: 2G

  # htmx Frontend (Primary - Server-side rendered)
  frontend:
    build:
      context: .
      dockerfile: docker/frontend.Dockerfile
    container_name: truthgraph-frontend
    environment:
      API_URL: http://api:8000
      FLASK_ENV: ${FLASK_ENV:-development}
      FLASK_DEBUG: ${FLASK_DEBUG:-1}
    volumes:
      # Mount templates and static files for hot reload
      - ./frontend/templates:/app/templates:ro
      - ./frontend/static:/app/static:ro
    ports:
      - "${FRONTEND_PORT:-5000}:5000"
    depends_on:
      api:
        condition: service_healthy
    networks:
      - truthgraph-network

  # React Frontend (Optional - for teams preferring React)
  frontend-react:
    build:
      context: ./frontend-react
      dockerfile: Dockerfile.dev
    container_name: truthgraph-frontend-react
    environment:
      VITE_API_URL: http://localhost:${API_PORT:-8000}
    volumes:
      # Mount source for hot module replacement
      - ./frontend-react/src:/app/src:ro
      - ./frontend-react/public:/app/public:ro
    ports:
      - "${REACT_PORT:-5173}:5173"
    depends_on:
      - api
    networks:
      - truthgraph-network
    profiles:
      - react  # Only start with: docker-compose --profile react up

networks:
  truthgraph-network:
    driver: bridge

volumes:
  # Named volumes are defined but we use bind mounts to .volumes/ for easier access
  postgres-data:
    driver: local
