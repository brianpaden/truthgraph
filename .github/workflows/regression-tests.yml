name: Regression Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      update_baseline:
        description: 'Update baseline after tests'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'

jobs:
  regression-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for git operations

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Install dependencies
        run: |
          uv sync --all-extras --dev

      - name: Start services
        run: |
          # Start PostgreSQL service
          sudo systemctl start postgresql

          # Wait for PostgreSQL to be ready
          until pg_isready; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done

      - name: Setup database
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/truthgraph_test
        run: |
          # Create test database
          sudo -u postgres psql -c "CREATE DATABASE truthgraph_test;"

          # Run migrations
          uv run alembic upgrade head

      - name: Load test corpus
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/truthgraph_test
        run: |
          # Load sample corpus for testing
          uv run python scripts/generate_sample_corpus.py
          uv run python scripts/embed_corpus.py

      - name: Run performance benchmarks
        run: |
          # Run embedding benchmarks
          uv run python scripts/benchmarks/benchmark_embeddings.py

          # Run NLI benchmarks
          uv run python scripts/benchmarks/benchmark_nli.py

      - name: Run accuracy tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/truthgraph_test
        run: |
          # Run accuracy baseline tests
          uv run pytest tests/accuracy/test_accuracy_baseline.py -v

      - name: Load baseline
        id: load_baseline
        run: |
          # Check if baseline exists
          if [ -f "tests/regression/baselines/baseline_$(date +%Y-%m-%d).json" ]; then
            echo "baseline_exists=true" >> $GITHUB_OUTPUT
          else
            echo "baseline_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Run regression tests
        if: steps.load_baseline.outputs.baseline_exists == 'true'
        run: |
          # Run performance regression tests
          uv run pytest tests/regression/test_performance_regression.py -v

          # Run accuracy regression tests
          uv run pytest tests/regression/test_accuracy_regression.py -v

      - name: Update baseline (if requested)
        if: |
          github.event.inputs.update_baseline == 'true' ||
          (github.event_name == 'push' && github.ref == 'refs/heads/main')
        run: |
          # Update baseline with current metrics
          uv run python scripts/update_baseline.py

          # Commit updated baseline
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add tests/regression/baselines/
          git commit -m "Update regression baseline [skip ci]" || echo "No changes to commit"
          git push || echo "No changes to push"

      - name: Upload regression results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: regression-results
          path: |
            tests/regression/results/
            tests/accuracy/results/
            scripts/benchmarks/results/
          retention-days: 30

      - name: Comment on PR (on failure)
        if: failure() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Try to read regression results
            let comment = '## âš ï¸ Regression Tests Failed\n\n';
            comment += 'Performance or accuracy regressions were detected.\n\n';
            comment += 'Please review the test results and ensure that:\n';
            comment += '- Performance changes are intentional and documented\n';
            comment += '- Accuracy changes are acceptable for the given changes\n\n';
            comment += 'If these changes are intentional, update the baseline after merging.\n';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Send Slack notification (on failure)
        if: failure() && github.event_name != 'pull_request'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "$SLACK_WEBHOOK_URL" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data "{\"text\":\"ðŸš¨ Regression tests failed on ${{ github.ref_name }}\"}" \
              $SLACK_WEBHOOK_URL
          fi

  summary:
    runs-on: ubuntu-latest
    needs: regression-tests
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "## Regression Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.regression-tests.result }}" == "success" ]; then
            echo "âœ… All regression tests passed!" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Regression tests failed. Please review the logs." >> $GITHUB_STEP_SUMMARY
          fi
